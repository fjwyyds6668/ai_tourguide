"""GraphRAG æ£€ç´¢ API"""
import logging
import asyncio
import json
from fastapi import APIRouter, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional, AsyncGenerator
from app.services.rag_service import rag_service, _clean_special_symbols
from app.services.session_service import session_service
from app.core.prisma_client import get_prisma
from app.models.interaction import Interaction

logger = logging.getLogger(__name__)

router = APIRouter()

class QueryRequest(BaseModel):
    query: str
    top_k: int = 5

class QueryResponse(BaseModel):
    vector_results: List[Dict[str, Any]]
    graph_results: List[Dict[str, Any]]
    query: str

class GenerateRequest(BaseModel):
    query: str
    session_id: Optional[str] = None
    character_id: Optional[int] = None
    use_rag: bool = True

class GenerateResponse(BaseModel):
    answer: str
    query: str
    context: str = ""
    session_id: str

@router.post("/search", response_model=QueryResponse)
async def hybrid_search(request: QueryRequest):
    """æ··åˆæ£€ç´¢"""
    try:
        results = await rag_service.hybrid_search(request.query, top_k=request.top_k)
        return QueryResponse(**results)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/vector-search")
async def vector_search(request: QueryRequest):
    """å‘é‡æœç´¢"""
    try:
        results = await rag_service.vector_search(request.query, top_k=request.top_k)
        return {"results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/graph-search")
async def graph_search(entity_name: str, relation_type: str = None, limit: int = 10):
    """å›¾æœç´¢"""
    try:
        results = await rag_service.graph_search(entity_name, relation_type, limit)
        return {"results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/generate", response_model=GenerateResponse)
async def generate_answer(request: GenerateRequest, background_tasks: BackgroundTasks):
    """ç”Ÿæˆå›žç­”ï¼ˆRAG + å¤šè½®å¯¹è¯ï¼‰ã€‚"""
    try:
        session_id = request.session_id
        if not session_id:
            session_id = session_service.create_session(request.character_id)
        else:
            session = session_service.get_session(session_id)
            if not session:
                session_id = session_service.create_session(request.character_id)
        # å¹¶è¡ŒåŠ è½½è§’è‰²æç¤ºè¯å’Œå¯¹è¯åŽ†å²
        async def load_character_prompt():
            if request.character_id:
                try:
                    prisma = await get_prisma()
                    character = await prisma.character.find_unique(where={"id": request.character_id})
                    if character and character.prompt:
                        return character.prompt
                except Exception as e:
                    logger.error(f"Failed to load character prompt: {e}")
            return None
        
        def load_conversation_history():
            return session_service.get_conversation_history(session_id)
        
        # å¹¶è¡ŒåŠ è½½è§’è‰²æç¤ºè¯å’Œå¯¹è¯åŽ†å²
        character_prompt, conversation_history = await asyncio.gather(
            load_character_prompt(),
            asyncio.to_thread(load_conversation_history)
        )
        
        result = await rag_service.generate_answer(
            query=request.query,
            context=None,
            use_rag=request.use_rag,
            conversation_history=conversation_history,
            character_prompt=character_prompt
        )
        answer = result["answer"]
        context = result.get("context", "")
        primary_attraction_id = result.get("primary_attraction_id")
        
        # ç«‹å³æ›´æ–°ä¼šè¯åŽ†å²ï¼ˆåŒæ­¥æ“ä½œï¼Œå¾ˆå¿«ï¼‰
        session_service.add_message(session_id, "user", request.query)
        session_service.add_message(session_id, "assistant", answer)
        
        # æ•°æ®åº“ä¿å­˜ä½¿ç”¨åŽå°ä»»åŠ¡ï¼Œä¸é˜»å¡žå“åº”
        def save_interaction():
            try:
                from app.core.database import SessionLocal
                from app.models.attraction import Attraction as AttractionModel
                db_local = SessionLocal()
                try:
                    aid = primary_attraction_id
                    # è‹¥ RAG æœªè¿”å›žæ™¯ç‚¹ IDï¼Œæ ¹æ®é—®é¢˜æ–‡æœ¬å°è¯•æŒ‰æ™¯ç‚¹åç§°åŒ¹é…ï¼ˆä¾¿äºŽæœåŠ¡æ¬¡æ•°ç»Ÿè®¡ï¼‰
                    if aid is None and request.query and request.query.strip():
                        q = (request.query or "").strip()
                        rows = (
                            db_local.query(AttractionModel.id, AttractionModel.name)
                            .filter(AttractionModel.name.isnot(None), AttractionModel.name != "")
                            .limit(200)
                            .all()
                        )
                        for row in rows:
                            name = row[1] if len(row) > 1 else None
                            if name and name in q:
                                aid = row[0]
                                break
                    interaction = Interaction(
                        session_id=session_id,
                        character_id=request.character_id,
                        query_text=request.query,
                        response_text=answer,
                        interaction_type="voice_query",
                        attraction_id=aid,
                    )
                    db_local.add(interaction)
                    db_local.commit()
                finally:
                    db_local.close()
            except Exception as e:
                logger.error(f"Failed to save interaction: {e}")
        
        background_tasks.add_task(save_interaction)
        
        return GenerateResponse(
            answer=answer,
            query=request.query,
            context=context,
            session_id=session_id
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/generate-stream")
async def generate_answer_stream(request: GenerateRequest, background_tasks: BackgroundTasks):
    """æµå¼ç”Ÿæˆå›žç­”ï¼ˆSSEï¼‰ï¼Œæ–‡æœ¬ä¸Ž TTS åŒæ­¥è¾“å‡º"""
    async def generate_stream() -> AsyncGenerator[str, None]:
        session_id = request.session_id
        if not session_id:
            session_id = session_service.create_session(request.character_id)
        else:
            session = session_service.get_session(session_id)
            if not session:
                session_id = session_service.create_session(request.character_id)
        
        # å¹¶è¡ŒåŠ è½½è§’è‰²æç¤ºè¯å’Œå¯¹è¯åŽ†å²
        async def load_character_prompt():
            if request.character_id:
                try:
                    prisma = await get_prisma()
                    character = await prisma.character.find_unique(where={"id": request.character_id})
                    if character and character.prompt:
                        return character.prompt
                except Exception as e:
                    logger.error(f"Failed to load character prompt: {e}")
            return None
        
        def load_conversation_history():
            return session_service.get_conversation_history(session_id)
        
        character_prompt, conversation_history = await asyncio.gather(
            load_character_prompt(),
            asyncio.to_thread(load_conversation_history)
        )
        
        # æ‰§è¡Œ RAG æ£€ç´¢ï¼ˆéžæµå¼ï¼Œä¸€æ¬¡æ€§èŽ·å–ä¸Šä¸‹æ–‡ï¼‰
        rag_results = None
        primary_attraction_id = None
        context = ""
        if request.use_rag:
            try:
                rag_results = await rag_service.hybrid_search(request.query, top_k=5)
                primary_attraction_id = rag_results.get("primary_attraction_id")
                context = rag_results.get("enhanced_context", "") or ""
            except Exception as e:
                logger.error(f"RAG search failed: {e}")
        
        # å‡†å¤‡ LLM æ¶ˆæ¯
        base_system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™¯åŒºAIå¯¼æ¸¸åŠ©æ‰‹ã€‚è¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨å‹å¥½ã€ä¸“ä¸šã€å‡†ç¡®çš„è¯­è¨€å›žç­”æ¸¸å®¢çš„é—®é¢˜ã€‚
å›žç­”è¦æ±‚ï¼š
1. åŸºäºŽæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›žç­”
2. è¯­è¨€ç®€æ´æ˜Žäº†ï¼Œé€‚åˆå£è¯­åŒ–è¡¨è¾¾
3. å¦‚æžœä¿¡æ¯ä¸è¶³ï¼Œè¯šå®žè¯´æ˜Ž
4. ä¸è¦ç¼–é€ ä¿¡æ¯
5. ä¸è¦é€éœ²ä»»ä½•å†…éƒ¨æ ‡è¯†ç¬¦/ç¼–å·/IDï¼ˆä¾‹å¦‚ kb_***ã€text_idã€session_id ç­‰ï¼‰ï¼›è‡ªæˆ‘ä»‹ç»æ—¶ä¹Ÿä¸è¦è¾“å‡ºä»»ä½•"ç¼–å·"
6. è¾“å‡ºå†…å®¹å¿…é¡»ä¸º"å¹²å‡€çš„çº¯æ–‡æœ¬"ï¼š
   - ç¦æ­¢ä½¿ç”¨ä»»ä½•è¡¨æƒ…ç¬¦å·ã€emojiã€é¢œæ–‡å­—ï¼ˆå¦‚ ðŸŒŸã€âœ¨ã€â¤ï¸ã€ðŸ˜Šã€1ï¸âƒ£ã€2ï¸âƒ£ ç­‰ï¼‰
   - ç¦æ­¢ä½¿ç”¨ Markdown æ ¼å¼ç¬¦å·ï¼ˆå¦‚ **ç²—ä½“**ã€*æ–œä½“*ã€# æ ‡é¢˜ã€- åˆ—è¡¨ç¬¦å·ç­‰ï¼‰
   - ç¦æ­¢ä½¿ç”¨è£…é¥°æ€§ç¬¦å·ï¼ˆå¦‚ ï½žã€~ã€â€”â€”ã€â€¦ã€â€¢ã€â–ªã€â–« ç­‰ï¼‰
   - åªä½¿ç”¨æ­£å¸¸ä¸­æ–‡æ ‡ç‚¹ï¼ˆï¼Œã€‚ï¼ï¼Ÿï¼šï¼›ï¼‰ä¸Žå¿…è¦çš„æ•°å­—ã€å•ä½
   - å¦‚éœ€åˆ—ä¸¾ï¼Œä½¿ç”¨"ç¬¬ä¸€"ã€"ç¬¬äºŒ"æˆ–"1."ã€"2."ç­‰çº¯æ–‡æœ¬æ ¼å¼ï¼Œä¸è¦ç”¨ç‰¹æ®Šç¬¦å·"""
        
        if character_prompt:
            system_prompt = f"{base_system_prompt}\n\nè§’è‰²è®¾å®šï¼š{character_prompt}"
        else:
            system_prompt = base_system_prompt
        
        messages = [{"role": "system", "content": system_prompt}]
        if conversation_history:
            messages.extend(conversation_history)
        
        user_prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{request.query}
ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context if context else "æ— é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯"}

è¯·åŸºäºŽä»¥ä¸Šä¿¡æ¯å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""
        messages.append({"role": "user", "content": user_prompt})
        
        # æµå¼è°ƒç”¨ LLM
        try:
            if not rag_service.llm_client:
                yield f"data: {json.dumps({'type': 'error', 'content': 'AIæœåŠ¡æœªé…ç½®'}, ensure_ascii=False)}\n\n"
                return
            
            # ä½¿ç”¨æµå¼ API
            from app.core.config import settings
            stream = rag_service.llm_client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=messages,
                temperature=0.7,
                max_tokens=1000,
                stream=True
            )
            
            full_answer = ""
            accumulated_text = ""
            
            # å‘é€ session_id
            yield f"data: {json.dumps({'type': 'session_id', 'content': session_id}, ensure_ascii=False)}\n\n"
            
            # å‘é€ primary_attraction_idï¼ˆç”¨äºŽåŽç»­ä¿å­˜äº¤äº’ï¼‰
            yield f"data: {json.dumps({'type': 'attraction_id', 'content': primary_attraction_id}, ensure_ascii=False)}\n\n"
            
            # æµå¼æŽ¥æ”¶å¹¶è½¬å‘æ–‡æœ¬
            for chunk in stream:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        content = delta.content
                        # æ¸…ç†ç‰¹æ®Šç¬¦å·
                        content = _clean_special_symbols(content)
                        if not content:
                            continue
                        full_answer += content
                        accumulated_text += content
                        
                        # å½“ç´¯ç§¯æ–‡æœ¬è¾¾åˆ°ä¸€å®šé•¿åº¦ï¼ˆå¦‚é‡åˆ°å¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰æ—¶ï¼Œå‘é€ä¸€æ®µç”¨äºŽ TTS
                        if any(punct in accumulated_text for punct in ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?']):
                            # æ‰¾åˆ°æœ€åŽä¸€ä¸ªæ ‡ç‚¹
                            last_punct_idx = max(
                                accumulated_text.rfind('ã€‚'),
                                accumulated_text.rfind('ï¼'),
                                accumulated_text.rfind('ï¼Ÿ'),
                                accumulated_text.rfind('.'),
                                accumulated_text.rfind('!'),
                                accumulated_text.rfind('?')
                            )
                            if last_punct_idx >= 0:
                                tts_chunk = accumulated_text[:last_punct_idx + 1]
                                accumulated_text = accumulated_text[last_punct_idx + 1:]
                                yield f"data: {json.dumps({'type': 'tts', 'content': tts_chunk}, ensure_ascii=False)}\n\n"
                        
                        # å‘é€æ–‡æœ¬å¢žé‡
                        yield f"data: {json.dumps({'type': 'text', 'content': content}, ensure_ascii=False)}\n\n"
            
            # å‘é€å‰©ä½™çš„ç´¯ç§¯æ–‡æœ¬ï¼ˆå¦‚æžœæœ‰ï¼‰
            if accumulated_text.strip():
                yield f"data: {json.dumps({'type': 'tts', 'content': accumulated_text.strip()}, ensure_ascii=False)}\n\n"
            
            # å‘é€å®Œæˆä¿¡å·
            yield f"data: {json.dumps({'type': 'done', 'content': full_answer}, ensure_ascii=False)}\n\n"
            
            # æ›´æ–°ä¼šè¯åŽ†å²
            session_service.add_message(session_id, "user", request.query)
            session_service.add_message(session_id, "assistant", full_answer)
            
            # åŽå°ä¿å­˜äº¤äº’è®°å½•
            def save_interaction():
                try:
                    from app.core.database import SessionLocal
                    from app.models.attraction import Attraction as AttractionModel
                    db_local = SessionLocal()
                    try:
                        aid = primary_attraction_id
                        if aid is None and request.query and request.query.strip():
                            q = (request.query or "").strip()
                            rows = (
                                db_local.query(AttractionModel.id, AttractionModel.name)
                                .filter(AttractionModel.name.isnot(None), AttractionModel.name != "")
                                .limit(200)
                                .all()
                            )
                            for row in rows:
                                name = row[1] if len(row) > 1 else None
                                if name and name in q:
                                    aid = row[0]
                                    break
                        interaction = Interaction(
                            session_id=session_id,
                            character_id=request.character_id,
                            query_text=request.query,
                            response_text=full_answer,
                            interaction_type="voice_query",
                            attraction_id=aid,
                        )
                        db_local.add(interaction)
                        db_local.commit()
                    finally:
                        db_local.close()
                except Exception as e:
                    logger.error(f"Failed to save interaction: {e}")
            
            background_tasks.add_task(save_interaction)
            
        except Exception as e:
            logger.error(f"Stream generation failed: {e}")
            yield f"data: {json.dumps({'type': 'error', 'content': str(e)}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(generate_stream(), media_type="text/event-stream")

